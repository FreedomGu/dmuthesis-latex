% This file was created with JabRef 2.8.
% Encoding: GBK

@ARTICLE{Barman2006,
  author = {Barman, P and Iqbal, Nadeem and Lee, SY},
  title = {Matrix Factorization Based Text Mining: Feature Extraction and Classification},
  journal = {Neural Information Processing},
  year = {2006},
  pages = {703--712},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://www.springerlink.com/index/N910300T07621125.pdf}
}

@ARTICLE{Berry2007,
  author = {Berry, MW and Browne, Murray and Langville, AN and Pauca, VP},
  title = {Algorithms and applications for approximate nonnegative matrix factorization},
  journal = {Computational Statistics and Data Analysis},
  year = {2007},
  pages = {--},
  number = {June 2006},
  keywords = {by the national science, conjugate gradient, constrained least squares,
	email surveillance, foundation under grant, nonnegative matrix factorization,
	research supported in part, spectral data analysis, text mining},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0167947306004191}
}

@ARTICLE{Boutsidis2008,
  author = {Boutsidis, C and Gallopoulos, E},
  title = {SVD based initialization: A head start for nonnegative matrix factorization},
  journal = {Pattern Recognition},
  year = {2008},
  volume = {41},
  pages = {1350--1362},
  number = {4},
  month = apr,
  keywords = {frobenius, low rank, nmf, nonnegative matrix factorization, perron,
	singular value decomposition, sparse factorization, sparse nmf, structured
	initialization, svd},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320307004359}
}

@ARTICLE{Buciu2006,
  author = {Buciu, I and Pitas, I},
  title = {NMF, LNMF, and DNMF modeling of neural receptive fields involved
	in human facial expression perception},
  journal = {Journal of Visual Communication and Image Representation},
  year = {2006},
  volume = {17},
  pages = {958--969},
  number = {5},
  keywords = {facial expressions, image representation, receptive fields},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S104732030600040X}
}

@ARTICLE{Cai2005,
  author = {Cai, D. and He, X. and Han, J.},
  title = {Document clustering using locality preserving indexing},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  year = {2005},
  volume = {17},
  pages = {1624--1637},
  number = {12},
  month = dec,
  comment = {Analysis on the relationship among LSI, LPI, and LDA indicates that
	the affinity graph is the key to distinguish these algorithms. The
	p-nearest neighbor graph makes LPI approximate to LDA, which is supervised.
	A complete graph makes LPI similar to LSI.},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1524963}
}

@ARTICLE{Chen2008,
  author = {Chen, Yanhua and Rege, Manjeet and Dong, Ming and Hua, Jing},
  title = {Non-negative matrix factorization for semi-supervised data clustering},
  journal = {Knowledge and Information Systems},
  year = {2008},
  volume = {17},
  pages = {355--379},
  number = {3},
  keywords = {non-negative matrix factorization, semi-supervised clustering},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://www.springerlink.com/index/10.1007/s10115-008-0134-6}
}

@ARTICLE{Cichocki2006,
  author = {Cichocki, Andrzej and Amari, Shun-ichi and Zdunek, R and Kompass,
	R and G},
  title = {Extended SMART algorithms for non-negative matrix factorization},
  journal = {Intelligence and Soft},
  year = {2006},
  pages = {1--15},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://www.springerlink.com/index/P2106451W36877MR.pdf}
}

@ARTICLE{Cichocki2008,
  author = {Cichocki, Andrzej and Lee, Hyekyoung and Kim, Yong-Deok and Choi,
	Seungjin},
  title = {Non-negative matrix factorization with Î±-divergence},
  journal = {Pattern Recognition Letters},
  year = {2008},
  volume = {29},
  pages = {1433--1440},
  number = {9},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865508000767}
}

@ARTICLE{Cichocki2007,
  author = {Cichocki, Andrzej and Zdunek, Rafal},
  title = {Regularized alternating least squares algorithms for non-negative
	matrix/tensor factorization},
  journal = {Advances in Neural Networks},
  year = {2007},
  pages = {793--802},
  number = {1},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://www.springerlink.com/index/Q8218LT427527826.pdf}
}

@ARTICLE{Cichocki2007a,
  author = {Cichocki, Andrzej and Zdunek, Rafal},
  title = {Multilayer nonnegative matrix factorization using projected gradient
	approaches},
  journal = {International Journal of Neural Systems},
  year = {2007},
  volume = {17},
  pages = {431--446},
  number = {6},
  keywords = {bss, multilayer nmf, nmf, nonnegative matrix factorization, projected
	gradient algorithms},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://www.bsp.brain.riken.jp/~zdunek/Cichocki_Zdunek_JNS.pdf}
}

@ARTICLE{Cichocki,
  author = {Cichocki, Andrzej and Zdunek, Rafal and Amari, S},
  title = {divergences for non-negative matrix factorization: Family of new
	algorithms},
  journal = {Independent Component Analysis and Blind},
  volume = {0},
  pages = {1--8},
  number = {1},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://www.springerlink.com/index/Q6M7V7G3017J203M.pdf}
}

@ARTICLE{Cichocki2006a,
  author = {Cichocki, A and Zdunek, R and Amari, S},
  title = {Csiszar's divergences for non-negative matrix factorization: Family
	of new algorithms},
  journal = {Independent Component Analysis and Blind},
  year = {2006},
  volume = {3889},
  pages = {32--39},
  comment = {Csiszar's divergences},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://www.springerlink.com/index/Q6M7V7G3017J203M.pdf}
}

@ARTICLE{Dhillon2006,
  author = {Dhillon, I and Sra, S},
  title = {Generalized nonnegative matrix approximations with Bregman divergences},
  journal = {Advances in neural information processing systems},
  year = {2006},
  volume = {77},
  pages = {18--31},
  comment = {Bregman divergences},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.78.6106&amp;rep=rep1&amp;type=pdf}
}

@ARTICLE{Ding2005,
  author = {Ding, Chris and He, Xiaofeng and Simon, HD},
  title = {the equivalence of nonnegative matrix factorization and spectral
	clustering},
  journal = {Proc. SIAM Data Mining Conf},
  year = {2005},
  pages = {--},
  number = {4},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.76.9476&amp;rep=rep1&amp;type=pdf}
}

@ARTICLE{Ding2010,
  author = {Ding, Chris and Li, Tao and Jordan, Michael I},
  title = {Convex and semi-nonnegative matrix factorizations.},
  journal = {IEEE transactions on pattern analysis and machine intelligence},
  year = {2010},
  volume = {32},
  pages = {45--55},
  number = {1},
  month = jan,
  abstract = {We present several new variations on the theme of nonnegative matrix
	factorization (NMF). Considering factorizations of the form X=FG(T),
	we focus on algorithms in which G is restricted to containing nonnegative
	entries, but allowing the data matrix X to have mixed signs, thus
	extending the applicable range of NMF methods. We also consider algorithms
	in which the basis vectors of F are constrained to be convex combinations
	of the data points. This is used for a kernel extension of NMF. We
	provide algorithms for computing these new factorizations and we
	provide supporting theoretical analysis. We also analyze the relationships
	between our algorithms and clustering algorithms, and consider the
	implications for sparseness of solutions. Finally, we present experimental
	results that explore the properties of these new methods.},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/19926898}
}

@ARTICLE{Donoho2004,
  author = {Donoho, D and Stodden, V},
  title = {When does non-negative matrix factorization give a correct decomposition},
  journal = {Advances in neural information processing},
  year = {2004},
  volume = {16},
  pages = {--},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.71.8086&amp;rep=rep1&amp;type=pdf}
}

@ARTICLE{Eggert2004,
  author = {Eggert, J and Korner, E},
  title = {Sparse coding and NMF},
  journal = {2004 IEEE International Joint Conference on Neural},
  year = {2004},
  volume = {2},
  pages = {2529--2533},
  number = {4},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:Sparse+coding+and+NMF#0}
}

@ARTICLE{Gu2010,
  author = {Gu, Quanquan and Zhou, Jie and Ding, Chris},
  title = {Collaborative Filtering: Weighted Nonnegative Matrix Factorization
	Incorporating User and Item Graphs},
  journal = {siam.org},
  year = {2010},
  pages = {199--210},
  keywords = {collaborative filtering, factorization, graph regularization, trix
	factorization, weighted nonnegative ma-, weighted nonnegative matrix
	tri-},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://www.siam.org/proceedings/datamining/2010/dm10_018_guq.pdf}
}

@INPROCEEDINGS{Guillamet2002,
  author = {Guillamet, David and Schiele, Bernt and Vitria, J},
  title = {Analyzing non-negative matrix factorization for image classification},
  booktitle = {International Conference on Pattern Recognition},
  year = {2002},
  volume = {1},
  pages = {2--5},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.19.717&amp;rep=rep1&amp;type=pdf}
}

@ARTICLE{Heiler2006,
  author = {Heiler, Matthias and Schn, Christoph},
  title = {Learning Sparse Representations by Non-Negative Matrix Factorization
	and Sequential Cone Programming},
  journal = {Journal of Machine Learning Research},
  year = {2006},
  volume = {7},
  pages = {1385--1407},
  keywords = {non-negative matrix factorization, optimization, reverse-convex programming,
	second-order cone programming, sequential convex, sparsity},
  owner = {Sean},
  timestamp = {2010.06.14}
}

@ARTICLE{Hoyer2004,
  author = {Hoyer, PO},
  title = {Non-negative matrix factorization with sparseness constraints},
  year = {2004},
  pages = {1--13},
  keywords = {data-adaptive representations, non-negative matrix factorization,
	sparseness},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://portal.acm.org/citation.cfm?id=1044709&amp;dl=}
}

@INPROCEEDINGS{Jenatton2010,
  author = {Jenatton, Rodolphe and Mairal, Julien and Obozinski, Guillaume and
	Bach, Francis},
  title = {Proximal Methods for Sparse Hierarchical Dictionary Learning},
  booktitle = {Proceedings of the 27th International Conference on Machine Learning},
  year = {2010},
  pages = {--},
  address = {Haifa, Israel},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://snowbird.djvuzone.org/2010/abstracts/103.pdf}
}

@ARTICLE{Kim2008a,
  author = {Kim, Hyunsoo and Park, Haesun},
  title = {Nonnegative Matrix Factorization Based on Alternating Nonnegativity
	Constrained Least Squares and Active Set Method},
  journal = {SIAM Journal on Matrix Analysis and Applications},
  year = {2008},
  volume = {30},
  pages = {713--713},
  number = {2},
  keywords = {15a23, active set method, ams subject classifications, conditions,
	karush-kuhn-tucker, kkt, lower rank approximation, means that all
	elements, method, non-negative matrix factorization, non-negativity
	constrained least squares, of, two block coordinate descent},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://link.aip.org/link/SJMAEL/v30/i2/p713/s1&Agg=doi}
}

@ARTICLE{Kim2008,
  author = {Kim, Jingu and Park, Haesun},
  title = {Toward Faster Nonnegative Matrix Factorization: A New Algorithm and
	Comparisons},
  journal = {2008 Eighth IEEE International Conference on Data Mining},
  year = {2008},
  pages = {353--362},
  month = dec,
  issn = {978-0-7695-3502-9},
  owner = {Sean},
  publisher = {Ieee},
  timestamp = {2010.06.14},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4781130}
}

@INPROCEEDINGS{Lee2001,
  author = {Lee, DD and Seung, HS},
  title = {Algorithms for non-negative matrix factorization},
  booktitle = {Advances in neural information processing systems},
  year = {2001},
  pages = {--},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.31.7566&amp;rep=rep1&amp;type=pdf}
}

@ARTICLE{Lee1999,
  author = {Lee, D D and Seung, H S},
  title = {Learning the parts of objects by non-negative matrix factorization.},
  journal = {Nature},
  year = {1999},
  volume = {401},
  pages = {788--91},
  number = {6755},
  month = oct,
  abstract = {Is perception of the whole based on perception of its parts? There
	is psychological and physiological evidence for parts-based representations
	in the brain, and certain computational theories of object recognition
	rely on such representations. But little is known about how brains
	or computers might learn the parts of objects. Here we demonstrate
	an algorithm for non-negative matrix factorization that is able to
	learn parts of faces and semantic features of text. This is in contrast
	to other methods, such as principal components analysis and vector
	quantization, that learn holistic, not parts-based, representations.
	Non-negative matrix factorization is distinguished from the other
	methods by its use of non-negativity constraints. These constraints
	lead to a parts-based representation because they allow only additive,
	not subtractive, combinations. When non-negative matrix factorization
	is implemented as a neural network, parts-based representations emerge
	by virtue of two properties: the firing rates of neurons are never
	negative and synaptic strengths do not change sign.},
  keywords = {Algorithms, Face, Humans, Learning, Models, Neurological, Perception,
	Perception: physiology, Semantics},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/10548103}
}

@INPROCEEDINGS{Lee2007,
  author = {Lee, Honglak and Battle, A and Raina, R and Ng, Andrew Y},
  title = {Efficient sparse coding algorithms},
  booktitle = {Advances in neural information},
  year = {2007},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.74.9685&amp;rep=rep1&amp;type=pdf}
}

@ARTICLE{Lewis1998,
  author = {Lewis, D.},
  title = {Naive (Bayes) at forty: The independence assumption in information
	retrieval},
  journal = {Machine Learning: ECML-98},
  year = {1998},
  pages = {4--15},
  __markedentry = {[zhibo:]},
  owner = {zhibo},
  publisher = {Springer},
  timestamp = {2012.10.29}
}

@ARTICLE{Li2006,
  author = {Li, Tao and Ding, Chris},
  title = {The Relationships Among Various Nonnegative Matrix Factorization
	Methods for Clustering},
  journal = {Sixth International Conference on Data Mining (ICDM'06)},
  year = {2006},
  pages = {362--371},
  number = {1},
  month = dec,
  issn = {0-7695-2701-7},
  keywords = {address the following important, ing, lar, matrix factorization, nmf
	convergence rate, nmf normalization, our study tries to, ques-, simultaneous
	cluster-, tions for matrix factorizations},
  owner = {Sean},
  publisher = {Ieee},
  timestamp = {2010.06.14},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4053063}
}

@ARTICLE{Li2010,
  author = {Li, Tao and Sindhwani, V and Ding, C and Zhang, Y},
  title = {Bridging Domains with Words: Opinion Analysis with Matrix Tri-factorizations},
  journal = {siam.org},
  year = {2010},
  pages = {293--302},
  keywords = {negative matrix factorization, non-, sentiment analysis, transfer
	learning},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://www.siam.org/proceedings/datamining/2010/dm10_026_lit.pdf}
}

@ARTICLE{Lin2007,
  author = {Lin, Chih-Jen},
  title = {Projected gradient methods for nonnegative matrix factorization.},
  journal = {Neural computation},
  year = {2007},
  volume = {19},
  pages = {2756--79},
  number = {10},
  month = oct,
  abstract = {Nonnegative matrix factorization (NMF) can be formulated as a minimization
	problem with bound constraints. Although bound-constrained optimization
	has been studied extensively in both theory and practice, so far
	no study has formally applied its techniques to NMF. In this letter,
	we propose two projected gradient methods for NMF, both of which
	exhibit strong optimization properties. We discuss efficient implementations
	and demonstrate that one of the proposed methods converges faster
	than the popular multiplicative update approach. A simple Matlab
	code is also provided.},
  keywords = {Algorithms, Artificial Intelligence, Image Interpretation, Computer-Assisted,
	Image Interpretation, Computer-Assisted: methods, Least-Squares Analysis,
	Models, Theoretical, Pattern Recognition, Automated, Pattern Recognition,
	Automated: methods},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/18188201}
}

@ARTICLE{Liu2010,
  author = {Liu, Jun and Chen, Songcan and Zhou, Zhi-Hua and Tan, Xiaoyang},
  title = {Generalized Low Rank Approximations of Matrices Revisited},
  journal = {Neural Networks, IEEE Transactions on},
  year = {2010},
  volume = {21},
  pages = {621--632},
  number = {4},
  month = feb,
  abstract = {Compared to singular value decomposition (SVD), generalized low-rank
	approximations of matrices (GLRAM) can consume less computation time,
	obtain higher compression ratio, and yield competitive classification
	performance. GLRAM has been successfully applied to applications
	such as image compression and retrieval, and quite a few extensions
	have been successively proposed. However, in literature, some basic
	properties and crucial problems with regard to GLRAM have not been
	explored or solved yet. For this sake, we revisit GLRAM in this paper.
	First, we reveal such a close relationship between GLRAM and SVD
	that GLRAM's objective function is identical to SVD's objective function
	except the imposed constraints. Second, we derive a lower bound of
	GLRAM's objective function, and discuss when the lower bound can
	be touched. Moreover, from the viewpoint of minimizing the lower
	bound, we answer one open problem raised by Ye (Machine Learning,
	2005), i.e., a theoretical justification of the experimental phenomenon
	that, under given number of reduced dimension, the lowest reconstruction
	error is obtained when the left and right transformations have equal
	number of columns. Third, we explore when and why GLRAM can perform
	well in terms of compression, which is a fundamental problem concerning
	the usability of GLRAM.},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5411923&isnumber=5441221}
}

@ARTICLE{Liu2004a,
  author = {Liu, W and Zheng},
  title = {Relative gradient speeding up additive updates for nonnegative matrix
	factorization},
  journal = {Neurocomputing},
  year = {2004},
  volume = {57},
  pages = {493--499},
  month = mar,
  keywords = {additive updates, multiplicative updates, nonnegative matrix factorization,
	relative gradient},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231204000049}
}

@ARTICLE{Liu2004,
  author = {Liu, W and Zheng, N},
  title = {Non-negative matrix factorization based methods for object recognition},
  journal = {Pattern Recognition Letters},
  year = {2004},
  volume = {25},
  pages = {893--897},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865504000479}
}

@ARTICLE{Mairal2010,
  author = {Mairal, Julien and Bach, Francis and Ponce, J and Sapiro, Guillermo},
  title = {Online learning for matrix factorization and sparse coding},
  journal = {Journal of Machine Learning Research},
  year = {2010},
  volume = {11},
  pages = {19--60},
  keywords = {basis pursuit, dictionary learning, ing, matrix factorization, negative
	matrix factorization, non-, online learning, sparse cod-, sparse
	principal component analysis, stochastic approximations, stochastic
	optimization},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.154.4185&amp;rep=rep1&amp;type=pdf}
}

@TECHREPORT{Martinsson2006,
  author = {Martinsson, P and Rokhlin, V and Tygert, M and A},
  title = {A randomized algorithm for the approximation of matrices},
  year = {2006},
  owner = {Sean},
  pages = {--},
  timestamp = {2010.06.14}
}

@ARTICLE{Martinsson,
  author = {Martinsson, P G},
  title = {A fast algorithm for compressing a matrix into a data-sparse format
	via randomized sampling},
  pages = {1--22},
  owner = {Sean},
  timestamp = {2010.06.14}
}

@INPROCEEDINGS{McCallum1998,
  author = {McCallum, A. and Nigam, K. and others},
  title = {A comparison of event models for naive bayes text classification},
  booktitle = {AAAI-98 workshop on learning for text categorization},
  year = {1998},
  volume = {752},
  pages = {41--48},
  organization = {Citeseer},
  __markedentry = {[zhibo:]},
  owner = {zhibo},
  timestamp = {2012.10.29}
}

@ARTICLE{Oja2004,
  author = {Oja, Erkki and Plumbley, Mark},
  title = {Blind separation of positive sources by globally convergent gradient
	search.},
  journal = {Neural computation},
  year = {2004},
  volume = {16},
  pages = {1811--25},
  number = {9},
  month = sep,
  abstract = {The instantaneous noise-free linear mixing model in independent component
	analysis is largely a solved problem under the usual assumption of
	independent nongaussian sources and full column rank mixing matrix.
	However, with some prior information on the sources, like positivity,
	new analysis and perhaps simplified solution methods may yet become
	possible. In this letter, we consider the task of independent component
	analysis when the independent sources are known to be nonnegative
	and well grounded, which means that they have a nonzero pdf in the
	region of zero. It can be shown that in this case, the solution method
	is basically very simple: an orthogonal rotation of the whitened
	observation vector into nonnegative outputs will give a positive
	permutation of the original sources. We propose a cost function whose
	minimum coincides with nonnegativity and derive the gradient algorithm
	under the whitening constraint, under which the separating matrix
	is orthogonal. We further prove that in the Stiefel manifold of orthogonal
	matrices, the cost function is a Lyapunov function for the matrix
	gradient flow, implying global convergence. Thus, this algorithm
	is guaranteed to find the nonnegative well-grounded independent sources.
	The analysis is complemented by a numerical simulation, which illustrates
	the algorithm.},
  keywords = {Algorithms, Computer Simulation, Humans, Image Processing, Computer-Assisted,
	Likelihood Functions, Linear Models, Nonlinear Dynamics, Signal Processing,
	Computer-Assisted},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/15265323}
}

@ARTICLE{Pascual-Montano2006,
  author = {Pascual-Montano, Alberto and Carazo, J M and Kochi, Kieko and Lehmann,
	Dietrich and Pascual-Marqui, Roberto D},
  title = {Nonsmooth nonnegative matrix factorization (nsNMF).},
  journal = {IEEE transactions on pattern analysis and machine intelligence},
  year = {2006},
  volume = {28},
  pages = {403--15},
  number = {3},
  month = mar,
  abstract = {We propose a novel nonnegative matrix factorization model that aims
	at finding localized, part-based, representations of nonnegative
	multivariate data items. Unlike the classical nonnegative matrix
	factorization (NMF) technique, this new model, denoted "nonsmooth
	nonnegative matrix factorization" (nsNMF), corresponds to the optimization
	of an unambiguous cost function designed to explicitly represent
	sparseness, in the form of nonsmoothness, which is controlled by
	a single parameter. In general, this method produces a set of basis
	and encoding vectors that are not only capable of representing the
	original data, but they also extract highly localized patterns, which
	generally lend themselves to improved interpretability. The properties
	of this new method are illustrated with several data sets. Comparisons
	to previously published methods show that the new nsNMF method has
	some advantages in keeping faithfulness to the data in the achieving
	a high degree of sparseness for both the estimated basis and the
	encoding vectors and in better interpretability of the factors.},
  keywords = {Algorithms, Artificial Intelligence, Computer Simulation, Diagnosis,
	Computer-Assisted, Diagnosis, Computer-Assisted: methods, Electroencephalography,
	Electroencephalography: methods, Face, Face: anatomy & histology,
	Humans, Image Interpretation, Computer-Assisted, Image Interpretation,
	Computer-Assisted: methods, Pattern Recognition, Automated, Pattern
	Recognition, Automated: methods, Sensitivity and Specificity, Software},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/16526426}
}

@INPROCEEDINGS{Pauca2004,
  author = {Pauca, VP and Shahnaz, F and Berry, MW and RJ},
  title = {Text mining using nonnegative matrix factorizations},
  booktitle = {Proceedings of the 2004 SIAM International Conference on Data Mining},
  year = {2004},
  pages = {--},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://books.google.com/books?hl=en&amp;lr=&amp;id=gcJVK9a9RR0C&amp;oi=fnd&amp;pg=PA452&amp;dq=Text+Mining+Using+Non-negative+Matrix+Factorizations&amp;ots=mNufZRwh7j&amp;sig=CA_xMduXLWc7FCQ13xMTaJtx3yg}
}

@ARTICLE{Schmidt,
  author = {Schmidt, M and Winther, Ole and Hansen, L},
  title = {Bayesian non-negative matrix factorization},
  journal = {Independent Component Analysis and Signal},
  pages = {--},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://www.springerlink.com/index/46306Q1484893835.pdf}
}

@ARTICLE{Schneider2010,
  author = {Schneider, Petra and Bunte, Kerstin and Stiekema, Han and Hammer,
	Barbara and Villmann, Thomas and Biehl, Michael},
  title = {Regularization in Matrix Relevance Learning.},
  journal = {IEEE transactions on neural networks / a publication of the IEEE
	Neural Networks Council},
  year = {2010},
  volume = {21},
  pages = {831--840},
  number = {5},
  month = mar,
  abstract = {In this paper, we present a regularization technique to extend recently
	proposed matrix learning schemes in learning vector quantization
	(LVQ). These learning algorithms extend the concept of adaptive distance
	measures in LVQ to the use of relevance matrices. In general, metric
	learning can display a tendency towards oversimplification in the
	course of training. An overly pronounced elimination of dimensions
	in feature space can have negative effects on the performance and
	may lead to instabilities in the training. We focus on matrix learning
	in generalized LVQ (GLVQ). Extending the cost function by an appropriate
	regularization term prevents the unfavorable behavior and can help
	to improve the generalization ability. The approach is first tested
	and illustrated in terms of artificial model data. Furthermore, we
	apply the scheme to benchmark classification data sets from the UCI
	Repository of Machine Learning. We demonstrate the usefulness of
	regularization also in the case of rank limited relevance matrices,
	i.e., matrix learning with an implicit, low-dimensional representation
	of the data.},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/20236882}
}

@ARTICLE{Sha2003,
  author = {Sha, F and Saul, LK and Lee, DD},
  title = {Multiplicative updates for nonnegative quadratic programming in support
	vector machines},
  journal = {Advances in neural information processing},
  year = {2003},
  pages = {--},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.14.8983&amp;rep=rep1&amp;type=pdf}
}

@INPROCEEDINGS{Shan2010,
  author = {Shan, Hanhuai and Banerjee, Arindam},
  title = {Residual Bayesian Co-clustering for Matrix Approximation},
  booktitle = {Proceedings of the SIAM International Conference on Data Mining,
	SDM 2010, April 29 - May 1, 2010, Columbus, Ohio, USA},
  year = {2010},
  pages = {223--234},
  publisher = {SIAM},
  owner = {Sean},
  timestamp = {2010.06.14}
}

@INCOLLECTION{Sheng2012,
  author = {Sheng, MingYang and Chen, YongQi and Dai, QingE},
  title = {A Novel Lagrangian Support Vector Machine and Application in the
	Crane Gear Fault Diagnosis System},
  booktitle = {Advances in Mechanical and Electronic Engineering},
  publisher = {Springer Berlin Heidelberg},
  year = {2012},
  editor = {Jin, David and Lin, Sally},
  volume = {176},
  series = {Lecture Notes in Electrical Engineering},
  pages = {369-373},
  note = {10.1007/978-3-642-31507-7_60},
  __markedentry = {[zhibo:6]},
  affiliation = {School of Science and Technology, Ningbo University, Ningbo, China},
  isbn = {978-3-642-31507-7},
  keyword = {Engineering},
  owner = {zhibo},
  timestamp = {2012.10.29},
  url = {http://dx.doi.org/10.1007/978-3-642-31507-7_60}
}

@INPROCEEDINGS{Wang2010,
  author = {Wang, Fei and Li, Ping},
  title = {Efficient Nonnegative Matrix Factorization with Random Projections},
  booktitle = {siam.org},
  year = {2010},
  pages = {281--292},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://www.siam.org/proceedings/datamining/2010/dm10_025_wangf.pdf}
}

@ARTICLE{Wang2005,
  author = {Wang, Yuan and Jia, Yunde and Hu, Changbo and Turk, Matthew},
  title = {Non-negative matrix factorization framework for face recognition},
  journal = {Journal of Pattern Recognition and and Artificial Intelligence},
  year = {2005},
  volume = {19},
  pages = {495--511},
  number = {4},
  keywords = {face recognition, fisher discriminant analysis, local facial feature,
	non-negative factorization},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.86.9289&amp;rep=rep1&amp;type=pdf}
}

@INPROCEEDINGS{Wang2004,
  author = {Wang, Yuan and Jia, Y and Hu, C and Turk, Matthew},
  title = {Fisher non-negative matrix factorization for learning local features},
  booktitle = {Asian Conference on Computer Vision},
  year = {2004},
  pages = {--},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.79.217}
}

@ARTICLE{Wild2004,
  author = {Wild, Stefan and Curry, James and Dougherty, Anne},
  title = {Improving non-negative matrix factorizations through structured initialization*
	1},
  journal = {Pattern Recognition},
  year = {2004},
  volume = {37},
  pages = {2217--2232},
  keywords = {compression, constrained optimization, data mining, k-means clustering,
	non-negative matrix factorization, rank reduction},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0031320304000937}
}

@ARTICLE{Witten2009,
  author = {Witten, DM and Tibshirani, R and Hastie, T},
  title = {A penalized matrix decomposition, with applications to sparse principal
	components and canonical correlation analysis},
  journal = {Biostatistics},
  year = {2009},
  pages = {--},
  keywords = {canonical correlation analysis, dna copy, integrative genomic analysis,
	l 1, matrix decomposition, number, principal component analysis,
	sparse principal component analysis, svd},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://biostatistics.oxfordjournals.org/cgi/content/abstract/10/3/515}
}

@INPROCEEDINGS{Wu2010,
  author = {Wu, Leting and Ying, Xiaowei and Wu, Xintao},
  title = {Reconstruction from Randomized Graph via Low Rank Approximation},
  booktitle = {Proceedings of the SIAM International Conference on Data Mining,
	SDM 2010, April 29 - May 1, 2010, Columbus, Ohio, USA},
  year = {2010},
  pages = {60--71},
  publisher = {SIAM},
  owner = {Sean},
  timestamp = {2010.06.14}
}

@INPROCEEDINGS{Xu2003a,
  author = {Xu, Baowen and Lu, Jianjiang and Huang, Gangshi},
  title = {A constrained non-negative matrix factorization in information retrieval},
  booktitle = {IEEE International Conference on Information Reuse},
  year = {2003},
  number = {60073012},
  pages = {273--277},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://scholar.google.com/scholar?hl=en&btnG=Search&q=intitle:A+constrained+non-negative+matrix+factorization+in+information+retrieval#0}
}

@INPROCEEDINGS{Xu2003,
  author = {Xu, W and Liu, X and Gong, Y},
  title = {Document clustering based on non-negative matrix factorization},
  booktitle = {Proceedings of the 26th annual international},
  year = {2003},
  pages = {267--273},
  keywords = {document clustering, non-negative matrix factorization},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://portal.acm.org/citation.cfm?id=860435.860485}
}

@ARTICLE{Yang2005,
  author = {Yang, CF and Ye, Mao and Zhao, Jing},
  title = {Document clustering based on nonnegative sparse matrix factorization},
  journal = {Advances in Natural Computation},
  year = {2005},
  pages = {557--563},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://www.springerlink.com/index/4X4WK1BE952NDHVK.pdf}
}

@INPROCEEDINGS{Zdunek2006,
  author = {Zdunek, Rafal and Cichocki, Andrzej},
  title = {Non-negative matrix factorization with quasi-Newton optimization},
  booktitle = {Artificial Intelligence and Soft ComputingâICAISC},
  year = {2006},
  pages = {1--10},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://www.springerlink.com/index/19374M78174943T2.pdf}
}

@INPROCEEDINGS{Zhang,
  author = {Zhang, Daoqiang and Zhou, Zhi-hua and Chen, Songcan},
  title = {Non-negative matrix factorization on kernels},
  booktitle = {PRICAI 2006: Trends in Artificial Intelligence},
  pages = {--},
  owner = {Sean},
  timestamp = {2010.06.14},
  url = {http://www.springerlink.com/index/J352469750234U60.pdf}
}

@comment{jabref-meta: selector_publisher:}

@comment{jabref-meta: selector_author:}

@comment{jabref-meta: selector_journal:}

@comment{jabref-meta: selector_keywords:}

